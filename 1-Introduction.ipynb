{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Say you work for a major social media website. Your boss always says “data drives all our decisions” and it seems to be true. Metrics are collected on all users of your website, terabytes of data stored in replicated databases.\n",
    "\n",
    "One day, your boss wants to know if college students are engaging in your website. You pull up the records for users in that age bracket and look at them one by one. The first person only spent half a second on your website before closing the tab — that doesn’t look good. But the second person was on the site for thirty minutes! That’s a running average of 15 minutes site time per user, but you still have half a million records to look at.\n",
    "\n",
    "On top of that, you need to compare it against other age brackets (and the average overall). That’s going to take a lot of time if you do it all by hand, and you’re still not sure what your methodology for proving college students spend enough time on your website to be “engaged”.\n",
    "\n",
    "When conducting data analysis, we want to say something meaningful about our data. Often, we want to know if a change or difference we see in a dataset is “real” or if it’s just a normal fluctuation or a result of the specific sample of people we have chosen to measure. A difference we observe in our data is only important if we can be reasonably sure that it is representative of the population as a whole, and reasonably sure that our result is repeatable.\n",
    "\n",
    "This question of whether a difference is significant or not is essential to making decisions based on that difference. Some instances where this might come up include:\n",
    "\n",
    "- Performing an A/B test — are the different observations really the results of different conditions (i.e., Condition A vs. Condition B)? Or just the result of random chance?\n",
    "- Conducting a survey — is the fact that men gave slightly different responses than women a real difference between men and women? Or just the result of chance?\n",
    "\n",
    "In this lesson, we will cover the fundamental concepts that will help us create tests to measure our confidence in our statistical results:\n",
    "\n",
    "- Sample means and population means\n",
    "- The Central Limit Theorem\n",
    "- Why we use hypothesis tests\n",
    "- What errors we can come across and how to classify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the Millennials Engaged?\n",
    "You work at the global megacorp social network SpyPy. SpyPy has 1.5 billion daily users, and you want to make sure that people in the millennial age bracket are engaging with your website. Your boss seems particularly frazzled by this question, and he's put it on you to find out. You decide that \"engagement\" means spending more than the average of seven minutes on the website. You fire up your data-science stack in Python and first check the average time -- which turns out to be near 11 whole minutes! But you can't really tell if they're *really* spending more time or if it's just random chance that a few of your users left the browser open and walked away. You write the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spypy\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "millennial_times = spypy.get_site_times_for_demographic('millennial')\n",
    "t_stat, p_val = ttest_1samp(millennial_times, 7)\n",
    "\n",
    "if p_val < .05:\n",
    "    print(\"The Millennials are engaged!\")\n",
    "else:\n",
    "    print(\"The Millennials are not engaged :(!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Output]: The Millennials are engaged!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpyPy: We're Significantly Different\n",
    "Well that's great news! Millennials are, for the most part, spending around 10 minutes on your website. But before you break out the champagne glasses your boss is in a frenzy again, this time about Metropolitan Statistical Areas (MSAs). You are tasked with finding if people in cooler climates post more pictures on SpyPy than people in warmer climates. You cross corroborate with weather data and run a statistical test on the info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "warmer_weather_picture_count = spypy.get_number_pictures_for_climate('hot')\n",
    "colder_weather_picture_count = spypy.get_number_pictures_for_climate('cold')\n",
    "\n",
    "t_stat, p_val = ttest_ind(warmer_weather_picture_count, colder_weather_picture_count)\n",
    "\n",
    "if p_val < .05:\n",
    "    print(\"People from colder climates post a different number of pictures compared to people from warmer climates\")\n",
    "else:\n",
    "    print(\"Climate doesn't appear to affect the number of pictures posted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Output]: Climate doesn't appear to affect the number of pictures posted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpyPy: Because We Care About Your Data\n",
    "Seems like climate *probably* doesn't really affect the number of times people post pictures. Not really sure why that would've been the case anyway. SpyPy has a new feature that you think will get people to interact with the website for longer: SpyPy Stories. It is preliminarily being launched to 8 million users and the internal goal is to get 2 million people to post SpyPy Stories in the first week. Unfortunately, only 1,997,893 people posted SpyPy Stories this week. We want to know if this is a significant difference from our goal -- did we pretty much meet it or did we seriously miss? You know how to answer this question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "number_of_trials = 8000000\n",
    "expected_successes = 2000000\n",
    "actual_successes = 1997893\n",
    "expected_success_rate = float(expected_successes) / float(number_of_trials)\n",
    "\n",
    "p_val = binom_test(actual_successes, n=number_of_trials, p=expected_success_rate)\n",
    "if p_val < 0.05:\n",
    "    print(\"We didn't hit our target by a significant amount\")\n",
    "else:\n",
    "    print(\"We just missed our target by a very small amount!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Output]: We just missed our target by a very small amount!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we came very close to hitting our target for SpyPy Stories! You've saved the day so many times already! Your boss comes by to thank you for all the hard work you put in today and says you've made significant contributions to the team. You tell her you're not sure if that's true, but you definitely have a way of finding out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
